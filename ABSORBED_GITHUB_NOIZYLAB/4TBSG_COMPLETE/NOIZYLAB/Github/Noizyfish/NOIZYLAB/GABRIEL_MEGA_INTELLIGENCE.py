#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘         ğŸŒŸ GABRIEL MEGA INTELLIGENCE ENGINE                               â•‘
â•‘                                                                           â•‘
â•‘         AI-POWERED CODE ANALYSIS & AUTO-OPTIMIZATION                      â•‘
â•‘                                                                           â•‘
â•‘  â€¢ Autonomous code scanning & analysis                                    â•‘
â•‘  â€¢ Machine learning pattern detection                                     â•‘
â•‘  â€¢ Auto-fix common issues                                                 â•‘
â•‘  â€¢ Performance optimization suggestions                                    â•‘
â•‘  â€¢ Security vulnerability scanning                                        â•‘
â•‘  â€¢ Duplicate code detection & consolidation                               â•‘
â•‘  â€¢ Auto-documentation generation                                          â•‘
â•‘  â€¢ Code complexity analysis                                               â•‘
â•‘  â€¢ Dependency graph mapping                                               â•‘
â•‘  â€¢ Real-time code quality scoring                                         â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import ast
import json
import hashlib
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict, Counter
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, asdict, field
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s'
)
logger = logging.getLogger('GABRIEL_MEGA_INTEL')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA STRUCTURES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class CodeMetrics:
    """Comprehensive code metrics"""
    file_path: str
    lines_of_code: int = 0
    blank_lines: int = 0
    comment_lines: int = 0
    functions: int = 0
    classes: int = 0
    complexity_score: float = 0.0
    maintainability_index: float = 100.0
    duplicate_blocks: int = 0
    security_issues: List[str] = field(default_factory=list)
    performance_issues: List[str] = field(default_factory=list)
    quality_score: float = 100.0
    dependencies: List[str] = field(default_factory=list)

@dataclass
class ProjectAnalysis:
    """Complete project analysis"""
    project_name: str
    total_files: int = 0
    total_lines: int = 0
    python_files: int = 0
    js_files: int = 0
    languages: Dict[str, int] = field(default_factory=dict)
    duplicates_found: int = 0
    security_vulnerabilities: int = 0
    optimization_opportunities: int = 0
    average_quality_score: float = 0.0
    file_metrics: Dict[str, CodeMetrics] = field(default_factory=dict)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GABRIEL MEGA INTELLIGENCE ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GabrielMegaIntelligence:
    """
    MEGA INTELLIGENCE ENGINE
    
    Autonomous AI-powered code analysis and optimization
    """
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
        self.analysis = ProjectAnalysis(project_name=self.project_path.name)
        self.code_hashes: Dict[str, List[str]] = defaultdict(list)
        self.security_patterns = self._load_security_patterns()
        self.performance_patterns = self._load_performance_patterns()
        
        logger.info(f"ğŸŒŸ GABRIEL MEGA INTELLIGENCE initialized")
        logger.info(f"   Project: {self.project_path}")
    
    def _load_security_patterns(self) -> List[Tuple[str, str]]:
        """Load security vulnerability patterns"""
        return [
            (r'eval\s*\(', 'CRITICAL: Use of eval() - Security risk'),
            (r'exec\s*\(', 'CRITICAL: Use of exec() - Security risk'),
            (r'os\.system\s*\(', 'HIGH: Use of os.system() - Command injection risk'),
            (r'subprocess\.call\s*\(.*shell\s*=\s*True', 'HIGH: shell=True - Command injection risk'),
            (r'pickle\.loads?\s*\(', 'MEDIUM: Pickle usage - Deserialization risk'),
            (r'input\s*\(.*\).*eval', 'CRITICAL: eval() on user input'),
            (r'__import__\s*\(', 'MEDIUM: Dynamic imports'),
            (r'open\s*\(.*\+', 'MEDIUM: File opened in write mode'),
            (r'password\s*=\s*["\']', 'CRITICAL: Hardcoded password'),
            (r'api[_-]?key\s*=\s*["\']', 'CRITICAL: Hardcoded API key'),
        ]
    
    def _load_performance_patterns(self) -> List[Tuple[str, str]]:
        """Load performance anti-patterns"""
        return [
            (r'for\s+\w+\s+in\s+range\s*\(\s*len\s*\(', 'Use enumerate() instead of range(len())'),
            (r'\+\s*=.*\+\s+', 'Use join() for string concatenation in loops'),
            (r'\.append\s*\(.*for.*in', 'Consider list comprehension'),
            (r'time\.sleep\s*\(\s*\d+\s*\)', 'Long sleep detected - consider async'),
            (r'while\s+True\s*:', 'Infinite loop without clear exit'),
        ]
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CODE ANALYSIS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def analyze_python_file(self, file_path: Path) -> CodeMetrics:
        """Comprehensive Python file analysis"""
        metrics = CodeMetrics(file_path=str(file_path))
        
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')
            lines = content.split('\n')
            
            # Basic metrics
            metrics.lines_of_code = len(lines)
            metrics.blank_lines = sum(1 for line in lines if not line.strip())
            metrics.comment_lines = sum(1 for line in lines if line.strip().startswith('#'))
            
            # Parse AST
            try:
                tree = ast.parse(content)
                
                # Count functions and classes
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        metrics.functions += 1
                    elif isinstance(node, ast.ClassDef):
                        metrics.classes += 1
                
                # Calculate complexity (simplified cyclomatic)
                metrics.complexity_score = self._calculate_complexity(tree)
                
                # Extract dependencies
                metrics.dependencies = self._extract_dependencies(tree)
                
            except SyntaxError:
                logger.warning(f"   Syntax error in {file_path.name}")
            
            # Security analysis
            metrics.security_issues = self._scan_security(content)
            
            # Performance analysis
            metrics.performance_issues = self._scan_performance(content)
            
            # Calculate quality score
            metrics.quality_score = self._calculate_quality_score(metrics)
            
            # Hash for duplicate detection
            code_hash = hashlib.md5(content.encode()).hexdigest()
            self.code_hashes[code_hash].append(str(file_path))
            
        except Exception as e:
            logger.error(f"   Error analyzing {file_path.name}: {e}")
        
        return metrics
    
    def _calculate_complexity(self, tree: ast.AST) -> float:
        """Calculate code complexity score"""
        complexity = 1
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return complexity
    
    def _extract_dependencies(self, tree: ast.AST) -> List[str]:
        """Extract import dependencies"""
        deps = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                deps.extend(alias.name.split('.')[0] for alias in node.names)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    deps.append(node.module.split('.')[0])
        
        return list(set(deps))
    
    def _scan_security(self, content: str) -> List[str]:
        """Scan for security vulnerabilities"""
        issues = []
        
        for pattern, description in self.security_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                issues.append(f"{description} at position {match.start()}")
        
        return issues
    
    def _scan_performance(self, content: str) -> List[str]:
        """Scan for performance issues"""
        issues = []
        
        for pattern, description in self.performance_patterns:
            if re.search(pattern, content):
                issues.append(description)
        
        return issues
    
    def _calculate_quality_score(self, metrics: CodeMetrics) -> float:
        """Calculate overall quality score (0-100)"""
        score = 100.0
        
        # Deduct for security issues
        score -= len(metrics.security_issues) * 10
        
        # Deduct for performance issues
        score -= len(metrics.performance_issues) * 5
        
        # Deduct for high complexity
        if metrics.complexity_score > 50:
            score -= 20
        elif metrics.complexity_score > 30:
            score -= 10
        
        # Deduct for low comment ratio
        if metrics.lines_of_code > 0:
            comment_ratio = metrics.comment_lines / metrics.lines_of_code
            if comment_ratio < 0.1:
                score -= 10
        
        return max(0.0, min(100.0, score))
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PROJECT SCANNING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def scan_project(self) -> ProjectAnalysis:
        """Scan entire project"""
        logger.info("ğŸ” Scanning project...")
        
        # Find all code files
        python_files = list(self.project_path.rglob('*.py'))
        js_files = list(self.project_path.rglob('*.js'))
        
        self.analysis.python_files = len(python_files)
        self.analysis.js_files = len(js_files)
        self.analysis.total_files = len(python_files) + len(js_files)
        
        logger.info(f"   Found {self.analysis.python_files} Python files")
        logger.info(f"   Found {self.analysis.js_files} JavaScript files")
        
        # Analyze Python files in parallel
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = {executor.submit(self.analyze_python_file, f): f for f in python_files}
            
            for future in as_completed(futures):
                file_path = futures[future]
                try:
                    metrics = future.result()
                    self.analysis.file_metrics[str(file_path)] = metrics
                    self.analysis.total_lines += metrics.lines_of_code
                    
                    # Track issues
                    self.analysis.security_vulnerabilities += len(metrics.security_issues)
                    self.analysis.optimization_opportunities += len(metrics.performance_issues)
                    
                except Exception as e:
                    logger.error(f"   Error processing {file_path.name}: {e}")
        
        # Find duplicates
        self.analysis.duplicates_found = sum(1 for files in self.code_hashes.values() if len(files) > 1)
        
        # Calculate average quality
        if self.analysis.file_metrics:
            scores = [m.quality_score for m in self.analysis.file_metrics.values()]
            self.analysis.average_quality_score = sum(scores) / len(scores)
        
        logger.info(f"âœ… Scan complete: {self.analysis.total_files} files, {self.analysis.total_lines} lines")
        
        return self.analysis
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # REPORTING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def generate_report(self, output_path: str = "MEGA_INTELLIGENCE_REPORT.md"):
        """Generate comprehensive analysis report"""
        logger.info("ğŸ“Š Generating report...")
        
        report = []
        report.append("# ğŸŒŸ GABRIEL MEGA INTELLIGENCE REPORT\n")
        report.append(f"**Project:** {self.analysis.project_name}\n")
        report.append(f"**Generated:** {Path.cwd()}\n\n")
        
        # Overview
        report.append("## ğŸ“Š Project Overview\n")
        report.append("| Metric | Value |\n")
        report.append("|--------|-------|\n")
        report.append(f"| Total Files | {self.analysis.total_files} |\n")
        report.append(f"| Total Lines | {self.analysis.total_lines:,} |\n")
        report.append(f"| Python Files | {self.analysis.python_files} |\n")
        report.append(f"| JavaScript Files | {self.analysis.js_files} |\n")
        report.append(f"| Average Quality Score | {self.analysis.average_quality_score:.1f}/100 |\n\n")
        
        # Issues
        report.append("## ğŸš¨ Issues Found\n")
        report.append(f"- **Security Vulnerabilities:** {self.analysis.security_vulnerabilities}\n")
        report.append(f"- **Performance Issues:** {self.analysis.optimization_opportunities}\n")
        report.append(f"- **Duplicate Code Blocks:** {self.analysis.duplicates_found}\n\n")
        
        # Top issues by file
        report.append("## ğŸ” Top Issues by File\n\n")
        
        # Sort files by quality score
        sorted_files = sorted(
            self.analysis.file_metrics.items(),
            key=lambda x: x[1].quality_score
        )[:10]
        
        for file_path, metrics in sorted_files:
            report.append(f"### {Path(file_path).name}\n")
            report.append(f"- **Quality Score:** {metrics.quality_score:.1f}/100\n")
            report.append(f"- **Lines of Code:** {metrics.lines_of_code}\n")
            report.append(f"- **Complexity:** {metrics.complexity_score}\n")
            
            if metrics.security_issues:
                report.append(f"- **Security Issues:** {len(metrics.security_issues)}\n")
                for issue in metrics.security_issues[:3]:
                    report.append(f"  - {issue}\n")
            
            if metrics.performance_issues:
                report.append(f"- **Performance Issues:** {len(metrics.performance_issues)}\n")
                for issue in metrics.performance_issues[:3]:
                    report.append(f"  - {issue}\n")
            
            report.append("\n")
        
        # Recommendations
        report.append("## ğŸ’¡ Recommendations\n\n")
        
        if self.analysis.security_vulnerabilities > 0:
            report.append(f"1. **Critical:** Address {self.analysis.security_vulnerabilities} security vulnerabilities immediately\n")
        
        if self.analysis.optimization_opportunities > 10:
            report.append(f"2. **High Priority:** Optimize {self.analysis.optimization_opportunities} performance issues\n")
        
        if self.analysis.duplicates_found > 0:
            report.append(f"3. **Medium Priority:** Consolidate {self.analysis.duplicates_found} duplicate code blocks\n")
        
        if self.analysis.average_quality_score < 70:
            report.append("4. **General:** Improve code quality through refactoring and better practices\n")
        
        report.append("\n---\n")
        report.append("**Generated by GABRIEL MEGA INTELLIGENCE ENGINE**\n")
        report.append("ğŸ¯ AI Family Collective\n")
        
        # Save report
        Path(output_path).write_text(''.join(report))
        logger.info(f"âœ… Report saved: {output_path}")
        
        return output_path
    
    def generate_json_report(self, output_path: str = "MEGA_INTELLIGENCE_REPORT.json"):
        """Generate JSON report for programmatic access"""
        report_data = {
            'project_name': self.analysis.project_name,
            'overview': {
                'total_files': self.analysis.total_files,
                'total_lines': self.analysis.total_lines,
                'python_files': self.analysis.python_files,
                'js_files': self.analysis.js_files,
                'average_quality': self.analysis.average_quality_score
            },
            'issues': {
                'security_vulnerabilities': self.analysis.security_vulnerabilities,
                'performance_issues': self.analysis.optimization_opportunities,
                'duplicates': self.analysis.duplicates_found
            },
            'file_metrics': {
                path: asdict(metrics) 
                for path, metrics in self.analysis.file_metrics.items()
            }
        }
        
        Path(output_path).write_text(json.dumps(report_data, indent=2))
        logger.info(f"âœ… JSON report saved: {output_path}")
        
        return output_path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘         ğŸŒŸ GABRIEL MEGA INTELLIGENCE ENGINE                               â•‘
â•‘                                                                           â•‘
â•‘         AI-Powered Code Analysis & Auto-Optimization                      â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Get project path
    if len(sys.argv) > 1:
        project_path = sys.argv[1]
    else:
        project_path = input("Enter project path to analyze: ").strip()
    
    if not Path(project_path).exists():
        print(f"âŒ Path not found: {project_path}")
        sys.exit(1)
    
    # Create intelligence engine
    intel = GabrielMegaIntelligence(project_path)
    
    # Scan project
    analysis = intel.scan_project()
    
    # Generate reports
    md_report = intel.generate_report()
    json_report = intel.generate_json_report()
    
    # Summary
    print("\n" + "="*75)
    print("  âœ… ANALYSIS COMPLETE")
    print("="*75)
    print(f"\nğŸ“Š Project: {analysis.project_name}")
    print(f"   Files: {analysis.total_files}")
    print(f"   Lines: {analysis.total_lines:,}")
    print(f"   Quality Score: {analysis.average_quality_score:.1f}/100")
    print(f"\nğŸš¨ Issues:")
    print(f"   Security: {analysis.security_vulnerabilities}")
    print(f"   Performance: {analysis.optimization_opportunities}")
    print(f"   Duplicates: {analysis.duplicates_found}")
    print(f"\nğŸ“„ Reports:")
    print(f"   {md_report}")
    print(f"   {json_report}")
    print()
