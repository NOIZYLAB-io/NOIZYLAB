"""
GABRIEL INFINITY KERNEL
The Temporal Operating System for M2 Ultra
GORUNFREE - Limits Removed

Modules:
  1. MemCellTemporal - 4D Timeline with conflict detection
  2. HyperCortex - 70B/8B brain with GC freeze
  3. Maestro - Async music composition
  4. MetalEars - Metal FFT audio analysis
  5. DreamChamber - PC Link & Infrastructure Control
"""

import asyncio
import os
import time
import gc
import hashlib
import subprocess
import socket
import struct
import json
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field

# NATIVE BRIDGE INTEGRATION (SHARED KERNEL)
import sys
sys.path.append("/Users/m2ultra/NOIZYLAB/PORTAL")
from gabriel_native import NativeBridge

# HYPERVELOCITY RUNTIME
try:
    import uvloop
    uvloop.install()
    UVLOOP = True
except ImportError:
    UVLOOP = False

try:
    import orjson
    def dumps(obj): return orjson.dumps(obj, option=orjson.OPT_SERIALIZE_NUMPY)
    def loads(s): return orjson.loads(s)
except ImportError:
    import json
    def dumps(obj): return json.dumps(obj).encode()
    def loads(s): return json.loads(s)


# CONFIG: M2 ULTRA INFINITY
MODELS = {
    "MASTER": "mlx-community/Meta-Llama-3-70B-Instruct-4bit",
    "GHOST":  "mlx-community/Meta-Llama-3-8B-Instruct-4bit",
    "MUSIC":  "facebook/musicgen-large"
}

VOL_PATH = Path("./data/gabriel_vol/")
DECAY_DAYS = 30

# NATIVE INTEGRATION
NATIVE_PATH = Path("/Users/m2ultra/NOIZYLAB/NATIVE")
HARDWARE_MONITOR_ACTIVE = True  # Enabled via /api/hardware
METAL_ACCELERATION_READY = True # Prototype validated


# ============================================================================
# MODULE 1: MEMCELL TEMPORAL (4D Timeline)
# ============================================================================

@dataclass
class TemporalEvent:
    id: str
    title: str
    start: datetime
    end: datetime
    created_at: float
    tags: List[str] = field(default_factory=list)
    priority: int = 5
    recurrence: Optional[str] = None
    
    def overlaps(self, other) -> bool:
        return self.start < other.end and self.end > other.start
    
    def to_dict(self) -> dict:
        return {
            "id": self.id, "title": self.title,
            "start": self.start.isoformat(), "end": self.end.isoformat(),
            "created_at": self.created_at, "tags": self.tags,
            "priority": self.priority, "recurrence": self.recurrence
        }
    
    @classmethod
    def from_dict(cls, data: dict):
        return cls(
            id=data["id"], title=data["title"],
            start=datetime.fromisoformat(data["start"]),
            end=datetime.fromisoformat(data["end"]),
            created_at=data["created_at"],
            tags=data.get("tags", []),
            priority=data.get("priority", 5),
            recurrence=data.get("recurrence")
        )


class MemCellTemporal:
    def __init__(self, path: Path = None):
        self.path = path or VOL_PATH / "temporal_graph.json"
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self.events: List[TemporalEvent] = []
        self.facts: Dict[str, Any] = {}
        self.interactions: List[Dict[str, str]] = []  # Session history
        self.archive: List[TemporalEvent] = []
        self._load()
    
    def _load(self):
        if self.path.exists():
            try:
                data = loads(self.path.read_bytes())
                self.events = [TemporalEvent.from_dict(e) for e in data.get("events", [])]
                self.facts = data.get("facts", {})
                self.interactions = data.get("interactions", [])
            except Exception:
                pass
    
    def save(self):
        data = {
            "events": [e.to_dict() for e in self.events],
            "facts": self.facts,
            "interactions": self.interactions[-20:], # Keep last 20 for context
            "archive": [e.to_dict() for e in self.archive],
            "updated_at": datetime.now(timezone.utc).isoformat()
        }
        self.path.write_bytes(dumps(data))

    def log_interaction(self, user: str, assistant: str):
        self.interactions.append({
            "timestamp": datetime.now().isoformat(),
            "user": user,
            "assistant": assistant
        })
        if len(self.interactions) > 50: # Persist a bit more but keep it lean
            self.interactions = self.interactions[-50:]
        self.save()

    def get_recent_history(self, n: int = 5) -> str:
        history = self.interactions[-n:]
        if not history: return ""
        lines = ["RECENT INTERACTIONS:"]
        for h in history:
            lines.append(f"  U: {h['user']}")
            lines.append(f"  A: {h['assistant'][:50]}...")
        return "\n".join(lines)
    
    def ingest_event(self, title: str, start: datetime, duration_mins: int = 60,
                     tags: List[str] = None, priority: int = 5) -> tuple:
        end = start + timedelta(minutes=duration_mins)
        event_id = hashlib.md5(f"{title}{start.isoformat()}".encode()).hexdigest()[:8]
        
        new_event = TemporalEvent(
            id=event_id, title=title, start=start, end=end,
            created_at=time.time(), tags=tags or [], priority=priority
        )
        
        conflicts = [e.title for e in self.events if new_event.overlaps(e)]
        
        if conflicts:
            return (False, f"TIME CONFLICT with: {', '.join(conflicts)}", conflicts)
        
        self.events.append(new_event)
        self.events.sort(key=lambda e: e.start)
        self.save()
        return (True, f"SCHEDULED: {title} ({start.strftime('%Y-%m-%d %H:%M')})", [])
    
    def get_upcoming(self, hours: int = 24) -> List[TemporalEvent]:
        now = datetime.now()
        end = now + timedelta(hours=hours)
        return [e for e in self.events if e.start >= now and e.start <= end]
    
    def get_context(self, n: int = 5) -> str:
        upcoming = self.get_upcoming(48)[:n]
        lines = ["TEMPORAL CONTEXT:"]
        for e in upcoming:
            lines.append(f"  - {e.title}: {e.start.strftime('%Y-%m-%d %H:%M')}")
        return "\n".join(lines) if len(lines) > 1 else "No upcoming events."
    
    def decay_old_events(self):
        cutoff = datetime.now() - timedelta(days=DECAY_DAYS)
        to_archive = [e for e in self.events if e.end < cutoff]
        self.archive.extend(to_archive)
        self.events = [e for e in self.events if e.end >= cutoff]
        self.save()
        return len(to_archive)


# ============================================================================
# MODULE 2: HYPER-CORTEX (Zero Latency Brain)
# ============================================================================

class HyperCortex:
    def __init__(self):
        self.master = None
        self.ghost = None
        self._generate = None
        self._loaded = False
        self.turbo_mode = False
    
    def load(self) -> bool:
        try:
            from mlx_lm import load, stream_generate
            self._generate = stream_generate  # Use stream_generate
            
            print("Loading Ghost (8B)...")
            self.ghost, self.ghost_tok = load(MODELS["GHOST"])
            
            print("Loading Master (70B)...")
            self.master, self.master_tok = load(MODELS["MASTER"])
            
            self._loaded = True
            print("CORTEX ONLINE.")
            return True
        except Exception as e:
            print(f"Cortex load error: {e}")
            return False
    
    async def think_stream(self, prompt: str, context: str = ""):
        """Async generator for streaming thoughts"""
        if not self._loaded:
            yield "Cortex not loaded. Using fallback."
            return
        
        gc.disable()
        try:
            full_prompt = f"[system]IDENTITY:GABRIEL. CONTEXT:{context}. DIRECTIVE:Concise.Execute.[/system][user]{prompt}[/user][assistant]"
            
            # Model selection: Forced Ghost in Turbo, else dynamic
            if self.turbo_mode:
                model, tok = self.ghost, self.ghost_tok
            else:
                model = self.ghost if len(prompt) < 50 else self.master
                tok = self.ghost_tok if len(prompt) < 50 else self.master_tok
            
            for response in self._generate(model, tok, prompt=full_prompt, max_tokens=200):
                yield response.text
                await asyncio.sleep(0)
                
        finally:
            gc.enable()
            gc.collect(0)


# ============================================================================
# MODULE 3: MAESTRO (Async Music)
# ============================================================================


class Maestro:
    def __init__(self):
        self.gen = None
        self.midi = None
        
    def load(self) -> bool:
        try:
            # Lazy import to avoid startup lag if not used
            from audiocraft.models import MusicGen
            import mido
            import numpy as np
            
            print("Loading MusicGen (AutoMaestro)...")
            # Small model for faster loading in dev
            self.gen = MusicGen.get_pretrained(MODELS["MUSIC"])
            try:
                self.midi = mido.open_output('Gabriel_Virtual_Out', virtual=True)
            except:
                self.midi = None 
            print("AUTO-MAESTRO ONLINE.")
            return True
        except ImportError:
            print("Maestro warning: 'audiocraft' not installed. Running in IDEA MODE (Text Only).")
            return "IDEA_MODE"
        except Exception as e:
            print(f"Maestro load error: {e}")
            return False
    
    async def jam_mode(self, cortex, style_input: Optional[str] = None):
        """Infinite Creative Loop"""
        print("\nüé∏ AUTO-MAESTRO JAM SESSION INIT...")
        
        styles = ["Cyberpunk Darksynth", "Ethereal Orchestral", "Hard Techno 140BPM", "Lo-Fi Study Beat", "Cinematic Sci-Fi"]
        style = style_input if style_input else random.choice(styles)
        
        print(f"   Generating Musical Concepts for Style: {style}...")
        
        # 1. GENERATE IDEA
        prompt = f"Generate a vivid description for a {style} music track. Keep it under 20 words."
        
        idea = ""
        try:
            async for chunk in cortex.think_stream(prompt):
                idea += chunk
        except Exception as e:
            idea = f"Spontaneous {style} improvisation"
            
        print(f"\nüéµ CONCEPT: {idea.strip()}")
        
        # 2. COMPOSE AUDIO (If possible)
        if self.gen:
            print("   Synthesizing Audio (10s)...")
            loop = asyncio.get_running_loop()
            def _gen():
                self.gen.set_generation_params(duration=10)
                wav = self.gen.generate([idea])
                return "Audio Rendered."
            try:
                await loop.run_in_executor(None, _gen)
                print("   ‚ñ∂Ô∏è PLAYING...")
            except Exception as e:
                print(f"   ‚ùå Synthesis failed: {e}")
        else:
            print("   (Audio Generation Skipped - Idea Mode)")
            
        return idea



# ============================================================================
# MODULE 4: METAL EARS (FFT Analysis)
# ============================================================================

class MetalEars:
    def __init__(self):
        self.stream = None
        self.peak = 0
        self._running = False
        self.mx = None
        self.fft = None
    
    def start(self) -> bool:
        try:
            import sounddevice as sd
            import mlx.core as mx
            import mlx.fft as fft
            
            # Pre-load MLX to avoid import in hot loop
            self.mx = mx
            self.fft = fft
            
            self.stream = sd.InputStream(
                callback=self._callback, channels=1, samplerate=48000, blocksize=2048
            )
            self.stream.start()
            self._running = True
            print("EARS ONLINE (48kHz Metal FFT).")
            return True
        except Exception as e:
            print(f"Ears error: {e}")
            return False
    
    def _callback(self, indata, frames, time_info, status):
        if not self._running or self.mx is None:
            return
            
        try:
            # Zero-copy where possible, but here we cast to tensor
            tensor = self.mx.array(indata.flatten())
            # Simple energy check or real FFT
            spectrum = self.fft.rfft(tensor)
            self.peak = self.mx.mean(self.mx.abs(spectrum)).item()
        except Exception:
            pass
    
    def stop(self):
        if self.stream:
            self.stream.stop()
            self._running = False


# ============================================================================
# MODULE 5: DREAMCHAMBER (PC Link)
# ============================================================================

class DreamChamberConnector:
    def __init__(self):
        self.ip = "10.0.0.160"
        self.mac = "XX:XX:XX:XX:XX:XX"  # Placeholder
        self.mount_script = Path(__file__).parent / "mount_pc_shares.sh"
        self.api_url = f"http://{self.ip}:8001"
        print("DREAMCHAMBER LINK ONLINE.")

    def ping(self) -> bool:
        try:
            subprocess.check_call(
                ['ping', '-c', '1', '-W', '500', self.ip], 
                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )
            return True
        except:
            return False

    def is_mounted(self) -> bool:
        return os.path.ismount("/Volumes/PC_Bridge")

    def wake(self):
        # Broadcast WOL
        if "XX" in self.mac:
            return "‚ùå MAC Address not configured in kernel."
        
        try:
            addrs = self.mac.split(':')
            hw_addr = struct.pack('BBBBBB', *[int(x, 16) for x in addrs])
            magic = b'\xff' * 6 + hw_addr * 16
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
            sock.sendto(magic, ('10.90.90.255', 9))
            sock.close()
            return f"‚ú® Magic Packet sent to {self.mac}"
        except Exception as e:
            return f"‚ùå WOL Error: {e}"

    def force_mount(self) -> str:
        if not self.mount_script.exists():
            return "‚ùå Mount script missing."
        
        res = subprocess.run([str(self.mount_script)], capture_output=True, text=True)
        if res.returncode == 0:
            return "‚úÖ Drive Mounted Successfully."
        else:
            return f"‚ùå Mount Failed: {res.stderr}"

    def status_report(self) -> str:
        online = "üü¢ ONLINE" if self.ping() else "üî¥ OFFLINE"
        mount = "üíæ MOUNTED" if self.is_mounted() else "‚ö†Ô∏è UNMOUNTED"
        return f"PC STATUS: {online} | {mount}"

    def speak(self, text: str) -> str:
        try:
            import requests
            requests.post(f"{self.api_url}/speak", json={"text": text}, timeout=1)
            return f"üó£Ô∏è PC Speaking: '{text}'"
        except: return "‚ùå PC Voice Unreachable"

    def launch(self, target: str) -> str:
        try:
            import requests
            requests.post(f"{self.api_url}/launch", json={"target": target}, timeout=1)
            return f"üöÄ PC Launching: '{target}'"
        except: return "‚ùå PC Launch Unreachable"

    def clipboard_read(self) -> str:
        try:
            import requests
            res = requests.get(f"{self.api_url}/clipboard", timeout=2)
            if res.status_code == 200:
                txt = res.json().get("content", "")
                return txt
            return ""
        except: return "ERROR"

    def clipboard_write(self, text: str) -> bool:
        try:
            import requests
            requests.post(f"{self.api_url}/clipboard", json={"content": text}, timeout=2)
            return True
        except: return False


# ============================================================================
# MODULE 6: UNIVERSAL SEARCH (The All-Seeing Eye)
# ============================================================================

class UniversalSearch:
    def __init__(self):
        self.code_db = Path("NOIZYLAB_DB/gabriel_index.db")
        self.vis_db = Path("NOIZYLAB_DB/visual_index.db")
        self.context = [] # Cache for /open command
        print("UNIVERSAL SEARCH ONLINE.")

    def search_code(self, query: str, limit=5) -> str:
        if not self.code_db.exists(): return "Code Index Offline."
        try:
            import sqlite3
            conn = sqlite3.connect(self.code_db)
            res = conn.execute("SELECT path, snippet(grif_search, 2, '<b>', '</b>', '...', 10) FROM grif_search WHERE grif_search MATCH ? ORDER BY rank LIMIT ?", (query, limit)).fetchall()
            conn.close()
            if not res: return "No code found."
            
            self.context = [r[0] for r in res] # Cache paths
            return "\n".join([f"[{i+1}] {r[0]}" for i, r in enumerate(res)])
        except Exception as e:
            return f"Search Error: {e}"

    def search_media(self, query: str, limit=5) -> str:
        if not self.vis_db.exists(): return "Visual Index Offline."
        try:
            import sqlite3
            conn = sqlite3.connect(self.vis_db)
            q = f"%{query}%"
            res = conn.execute("SELECT path, media_type, volume FROM assets WHERE filename LIKE ? LIMIT ?", (q, limit)).fetchall()
            conn.close()
            if not res: return "No media found."
            
            self.context = [r[0] for r in res] # Cache paths
            return "\n".join([f"[{i+1}] [{r[1].upper()}] {r[0]}" for i, r in enumerate(res)])
        except Exception as e:
            return f"Search Error: {e}"

    def open_item(self, index: int) -> str:
        if index < 1 or index > len(self.context):
            return f"‚ùå Invalid Index. Range: 1-{len(self.context)}"
        
        path = self.context[index-1]
        try:
            subprocess.call(['open', path])
        except Exception as e:
            return f"‚ùå Launch Failed: {e}"
            
# ============================================================================
# DREAMCHAMBER API SERVER (AIOHTTP)
# ============================================================================

import orjson
from aiohttp import web

async def handle_status(request):
    """Full system status for DreamChamber"""
    brain = request.app['brain']
    mem = request.app['mem']
    dream = request.app['dream']
    
    # OS Metrics
    try:
        cpu = subprocess.check_output("top -l 1 | grep 'CPU usage'", shell=True).decode().strip()
        ram = subprocess.check_output("top -l 1 | grep 'PhysMem'", shell=True).decode().strip()
    except:
        cpu = "N/A"
        ram = "N/A"
        
    data = {
        "status": "ONLINE",
        "turbo_mode": brain.turbo_mode,
        "history": mem.interactions[-10:],
        "cpu_usage": cpu,
        "ram_usage": ram,
        "pc_status": dream.status_report()
    }
    return web.Response(text=orjson.dumps(data).decode(), content_type='application/json')

async def handle_command(request):
    """Execute a command from DreamChamber Console"""
    data = await request.json()
    cmd = data.get("command", "")
    app_instance = request.app['instance']
    
    # We need a way to inject this command into the main loop or handle it directly
    # For now, let's process it through a simplified logic
    print(f"üåê API COMMAND: {cmd}")
    
    # Simulate the main loop logic for this command (limited for safety)
    response = f"GABRIEL: Received '{cmd}'. Processing..."
    
    return web.Response(text=orjson.dumps({"response": response}).decode(), content_type='application/json')

async def start_api_server(brain, mem, dream, instance):
    app = web.Application()
    app['brain'] = brain
    app['mem'] = mem
    app['dream'] = dream
    app['instance'] = instance
    
    app.router.add_get('/api/gabriel/status', handle_status)
    app.router.add_post('/api/gabriel/command', handle_command)
    
    # CORS
    async def cors_middleware(app, handler):
        async def middleware(request):
            response = await handler(request)
            response.headers['Access-Control-Allow-Origin'] = '*'
            response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
            response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
            return response
        return middleware
    
    app.middlewares.append(cors_middleware)
    
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', 5175)
    await site.start()
    print("üåê DREAMCHAMBER API SERVER ONLINE (PORT 5175)")


# ============================================================================
# THE INFINITY LOOP
# ============================================================================

async def main():
    print("")
    print("=" * 60)
    print("  GABRIEL INFINITY - TEMPORAL OPERATING SYSTEM")
    print("  GORUNFREE | M2 ULTRA | ZERO LATENCY")
    print("=" * 60)
    print("")
    
    # Initialize Modules
    mem = MemCellTemporal()
    brain = HyperCortex()
    music = Maestro()
    ears = MetalEars()
    dream = DreamChamberConnector()
    eye = UniversalSearch()
    native = NativeBridge()
    
    # Load what's available
    brain.load()
    music.load()
    
    # MetalEars (Local Mic) - Disabled by default for iPhone exclusivity
    if os.environ.get("ENABLE_LOCAL_MIC") == "1":
        print("  EARS:  [ON] Listening on Local Mic")
        ears.start()
    else:
        print("  EARS:  [OFF] Remote Mic Only (iPhone)")
    
    print("")
    print("SYSTEM READY. Type 'exit' to quit.")
    print("")

    # --- PACK HEARTBEAT ---
    # API Server
    await start_api_server(brain, mem, dream, "main")
    
    print("GABRIEL INFINITY KERNEL ONLINE.")
    scanner_pid = "OFFLINE"
    try:
        res = subprocess.check_output(["pgrep", "-f", "visual_scanner.py"]).decode().strip()
        if res: scanner_pid = f"FLOWING (PID {res.split()[0]})"
    except: pass
    print(f"   üåä FISHNET FLOW:   {scanner_pid}")
    
    dash_pid = "OFFLINE"
    try:
        res = subprocess.check_output(["pgrep", "-f", "streamlit run"]).decode().strip()
        if res: dash_pid = f"WATCHING (PID {res.split()[0]})"
    except: pass
    print(f"   üëÅÔ∏è  DASHBOARD:     {dash_pid}")
    
    pc_status = "UNREACHABLE"
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(0.2)
        if s.connect_ex(("10.0.0.160", 445)) == 0: pc_status = "LINKED üü¢"
        s.close()
    except: pass
    print(f"   üíª DREAMCHAMBER:  {pc_status}")
    print("\n   [COMMANDS]: /say <text>, /jam, /flow, /code, /find, /help")
    
    loop = asyncio.get_running_loop()

    # --- SENTINEL AWAKENING (Async Task) ---
    async def watch_filesystem():
        # Watch the Local Workspaces
        target = "/Users/m2ultra/.gemini/antigravity/playground/iridescent-station/NOIZYLAB_WORKSPACES_LOCAL"
        async for event in native.stream_sentry_events(target):
             path = event.get("path", "")
             # Filter noise (git, pycache)
             if any(x in path for x in [".git", "__pycache__", ".DS_Store"]): continue
             
             print(f"üëÅÔ∏è  SENTINEL: Change detected at {path.split('/')[-1]}")
             # In future: mem.ingest_event(...)

    # Fire and forget the sentinel
    loop.create_task(watch_filesystem())
    
    while True:
        try:
            # Get Input
            user_in = await loop.run_in_executor(None, input, "GABRIEL >> ")
            if not user_in: continue
            
            # --- TRUE FLOW COMMANDS ---
            if "/say" in user_in:
                text = user_in.replace("/say", "").strip()
                if text:
                    print(f"üó£Ô∏è  Processing Voice: '{text}'...")
                    # 1. ATTEMPT AVATAR API
                    try:
                        cmd = f'curl -m 2 -X POST -H "Content-Type: application/json" -d \'{{"text": "{text}"}}\' http://localhost:8000/api/speak > /dev/null 2>&1'
                        res = subprocess.call(cmd, shell=True)
                        if res != 0: raise Exception("Avatar Offline")
                        print(f"‚ú® Avatar Speaking.")
                    except:
                        # 2. FALLBACK TO LOCAL MACOS SAY
                        print(f"üì¢ Fallback: Local Voice Synthesis...")
                        subprocess.call(['say', text])
                continue

            if "/search" in user_in:
                query = user_in.replace("/search", "").strip()
                print(f"  üîç SEARCHING UNIVERSE FOR: '{query}'...")
                
                print("  [MEDIA/PROJECTS]")
                print(eye.search_media(query))
                
                print("\n  [CODE_VAULT]")
                print(eye.search_code(query))
                continue

            if "/show" in user_in:
                arg = user_in.replace("/show", "").strip()
                if arg.isdigit():
                    idx = int(arg)
                    print(f"üëÅÔ∏è  PREVIEWING ITEM [{idx}]...")
                    msg = eye.open_item(idx)
                    print(msg)
                else:
                    print(f"üîç Finding and Showing: '{arg}'...")
                    eye.search_media(arg, limit=1)
                    if eye.context:
                        print(eye.open_item(1))
                    else:
                        print("‚ùå Nothing found to show.")
                continue

            if "/jam" in user_in:
                style_req = user_in.replace("/jam", "").strip()
                await music.jam_mode(brain, style_input=style_req if style_req else None)
                continue

            if "/check" in user_in:
                print("ü©∫ INITIATING SYSTEM DIAGNOSTICS...")
                from gabriel_doctor import GabrielDoctor
                doc = GabrielDoctor()
                auto_heal = "--heal" in user_in
                doc.run(auto_heal=auto_heal)
                continue

            if "/native" in user_in:
                print("‚ö° BRIDGE: Accessing M2 Ultra Native Modules...")
                # 1. Check Metal
                metal_ok = await native.check_metal_status()
                status_icon = "üü¢" if metal_ok else "üî¥"
                print(f"   GPU COMPUTE: {status_icon} (Metal 3)")
                
                # 2. Check Sentry (FSEvents)
                sentry_path = native.sentry_bin
                sentry_ok = sentry_path.exists()
                sentry_icon = "ACTIVE" if sentry_ok else "MISSING"
                print(f"   FILE SENTRY: {sentry_icon} (High-Freq Monitor)")
                continue

            if "/benchmark" in user_in:
                print("üè≠ METAL FOUNDRY: Running M2 Ultra Stress Test...")
                print("   [MATRIX_MUL_4096_FP32]")
                score = await native.run_benchmark()
                print(f"   üöÄ RESULT: {score}")
                continue

            if "/automation" in user_in:
                parts = user_in.split(" ", 2) # /automation <cmd> <json>
                if len(parts) < 2:
                    print("Usage: /automation <command> [json_payload]")
                    continue
                
                cmd = parts[1]
                payload = {}
                if len(parts) > 2:
                    try:
                        payload = json.loads(parts[2])
                    except:
                        print("‚ùå Invalid JSON payload")
                        continue
                
                print(f"ü§ñ AUTOMATION: Executing '{cmd}'...")
                res = await native.run_automation(cmd, payload)
                print(f"   STATUS: {res.get('status', 'unknown')}")
                if 'message' in res: print(f"   MSG: {res['message']}")
                continue

            if "/sys" in user_in:
                print("üìä GABRIEL SYSTEM METRICS (M2 ULTRA)")
                try:
                    # CPU usage
                    cpu_res = subprocess.check_output("top -l 1 | grep 'CPU usage'", shell=True).decode().strip()
                    # Memory usage
                    mem_res = subprocess.check_output("top -l 1 | grep 'PhysMem'", shell=True).decode().strip()
                    # Disk usage
                    disk_res = subprocess.check_output("df -h / | tail -1", shell=True).decode().strip()
                    parts = disk_res.split()
                    disk_info = f"Disk: {parts[2]} used of {parts[1]} ({parts[4]} occupied)"

                    print(f"  üî• {cpu_res}")
                    print(f"  üß† {mem_res}")
                    print(f"  üíæ {disk_info}")
                except Exception as e:
                    print(f"  ‚ùå Metrics Error: {e}")
                continue

            if "/turbo" in user_in:
                brain.turbo_mode = not brain.turbo_mode
                status = "ON (Ghost Only)" if brain.turbo_mode else "OFF (Dynamic Master/Ghost)"
                print(f"‚ö° TURBO MODE: {status}")
                continue
                
            if user_in.lower() == "exit": break
            
            if user_in.lower() == "exit":
                break
            
            if not user_in.strip():
                continue
            
            # PROMPT PROCESSING
            prompt_lower = user_in.lower()
            
            # --- SKILL: DREAMCHAMBER (PC) ---
            if "pc" in prompt_lower or "dreamchamber" in prompt_lower:
                if "status" in prompt_lower or "check" in prompt_lower:
                    print(f"GABRIEL: {dream.status_report()}")
                    continue
                if "wake" in prompt_lower or "boot" in prompt_lower:
                    print(f"GABRIEL: {dream.wake()}")
                    continue
                if "mount" in prompt_lower or "connect" in prompt_lower:
                    print("GABRIEL: Attempting connection...")
                    print(f"GABRIEL: {dream.force_mount()}")
                if "/pc launch" in user_in:
                    tgt = user_in.split("/pc launch")[1].strip()
                    print(dream.launch(tgt))
                    continue

                if "/pc copy" in user_in:
                    print("üß† MIND-MELD: Syncing PC Clipboard to Mac...")
                    txt = dream.clipboard_read()
                    if txt and txt != "ERROR":
                        p = subprocess.Popen(['pbcopy'], stdin=subprocess.PIPE)
                        p.communicate(input=txt.encode('utf-8'))
                        print(f"‚úÖ Synced: '{txt[:30]}...'")
                    else:
                        print("‚ùå Failed to read PC Clipboard.")
                    continue
                
                if "/pc paste" in user_in:
                    print("üß† MIND-MELD: Sending Mac Clipboard to PC...")
                    # Read Mac Clipboard
                    txt = subprocess.check_output(['pbpaste']).decode('utf-8')
                    if dream.clipboard_write(txt):
                        print(f"‚úÖ Sent: '{txt[:30]}...'")
                    else:
                        print("‚ùå Failed to write to PC.")
                    continue

                if "/open" in user_in:
                    arg = user_in.replace("/open", "").strip()
                    if arg.isdigit():
                        print(eye.open_item(int(arg)))
                    else:
                        print(f"üöÄ Launching match for '{arg}'...")
                        eye.search_code(arg, limit=1) # Try code first for /open
                        if eye.context:
                            print(eye.open_item(1))
                        else:
                            eye.search_media(arg, limit=1)
                            if eye.context:
                                print(eye.open_item(1))
                            else:
                                print("‚ùå Nothing found.")
                    continue
                
                # REMOTE CONTROL
                if "/pc say" in user_in:
                    txt = user_in.split("/pc say")[1].strip()
                    print(dream.speak(txt))
                    continue
                
                if "/pc launch" in user_in:
                    tgt = user_in.split("/pc launch")[1].strip()
                    print(dream.launch(tgt))
                    continue

            # --- SKILL: UNIVERSAL SEARCH ---
            if "/code" in user_in:
                q = user_in.replace("/code", "").strip()
                print(f"Searching Codebase for '{q}'...")
                print(eye.search_code(q))
                continue
                
            if "/find" in user_in or "/media" in user_in:
                q = user_in.replace("/find", "").replace("/media", "").strip()
                print(f"Searching Visual Vault for '{q}'...")
                print(eye.search_media(q))
                continue

            if "/flow" in user_in:
                print("\nüåä THE GABRIEL FLOW üåä")
                print("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
                
                # 1. CORE
                print("üîπ [M2 ULTRA CORE]")
                print(f"   System:   ONLINE")
                
                # 2. DREAMCHAMBER
                pc_stat = dream.status_report()
                if "ONLINE" in pc_stat:
                    print(f"   PC Link:  üü¢ {pc_stat}")
                    print(f"   RME Audio: üü¢ LINKED")
                else:
                    print(f"   PC Link:  üî¥ {pc_stat}")
                
                # 3. STUDIO
                try:
                    res = subprocess.check_output(["pgrep", "-f", "UA Mixer Engine"]).decode().strip()
                    if res: print("   UAD Core: üü¢ ONLINE")
                    else: print("   UAD Core: ‚ö™ OFFLINE")
                except: print("   UAD Core: ‚ö™ OFFLINE")

                # 4. FISHNET
                try:
                    res = subprocess.check_output(["pgrep", "-f", "visual_scanner.py"]).decode().strip()
                    if res: print(f"   Scanner:  üü¢ FLOWING (PID {res.split()[0]})")
                    else: print("   Scanner:  ‚ö™ IDLE")
                except: print("   Scanner:  ‚ö™ IDLE")

                # 5. FACE
                print("   Avatar:   üü¢ READY (Port 8000)")
                
                print("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
                continue

            # --- SKILL: TEMPORAL (SCHEDULE) ---
            if "schedule" in prompt_lower:
                now = datetime.now()
                success, msg, conflicts = mem.ingest_event(
                    user_in.replace("schedule", "").strip() or "Task",
                    now + timedelta(hours=1), 60
                )
                print(f"result: {msg}")
                continue
            
            # --- SKILL: MAESTRO (MUSIC) ---
            if "/music" in user_in:
                result = await music.compose(user_in.replace("/music", "").strip())
                print(f"MAESTRO: {result}")
                continue
            
            # --- SKILL: CONTEXT QUERY ---
            if "upcoming" in prompt_lower:
                print(mem.get_context())
                continue
            
            # --- SKILL: INTELLECTUAL EXECUTION (DEFAULT) ---
            temporal_ctx = mem.get_context(3)
            recent_history = mem.get_recent_history(3)
            pc_context = f" [PC: {dream.status_report()}]"
            
            full_context = f"{temporal_ctx}\n{recent_history}\n{pc_context}"
            
            print("GABRIEL: ", end="", flush=True)
            
            complete_thought = ""
            async for token in brain.think_stream(user_in, full_context):
                print(token, end="", flush=True)
                complete_thought += token
            print("\n")
            
            # LOG FOR MEMORY
            mem.log_interaction(user_in, complete_thought)
            
            gc.collect(0)
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"ERROR: {e}")
    
    ears.stop()
    print("SYSTEM HALT.")


if __name__ == "__main__":
    asyncio.run(main())
