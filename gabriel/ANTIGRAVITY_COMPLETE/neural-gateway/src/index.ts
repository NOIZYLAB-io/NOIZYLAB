/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * NEURAL GATEWAY - MC96ECOUNIVERSE AI Model Router
 * Smart routing across 20+ AI models with load balancing + caching + analytics
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import { Hono } from 'hono';
import { cors } from 'hono/cors';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TYPES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface Env {
  AI: any;
  KV: KVNamespace;
}

interface ModelConfig {
  id: string;
  name: string;
  category: 'llm' | 'image' | 'audio' | 'embedding' | 'vision' | 'code';
  provider: string;
  contextLength?: number;
  speed: 'fast' | 'medium' | 'slow';
  quality: 'basic' | 'good' | 'excellent';
  cost: 'free' | 'low' | 'medium' | 'high';
}

interface RoutingStrategy {
  type: 'fastest' | 'best_quality' | 'lowest_cost' | 'balanced' | 'specific';
  fallback?: boolean;
  modelId?: string;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MODEL REGISTRY - ALL 20+ WORKERS AI MODELS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const MODEL_REGISTRY: Record<string, ModelConfig> = {
  // ğŸ§  LLMs - Text Generation
  'llama-3.1-70b': {
    id: '@cf/meta/llama-3.1-70b-instruct',
    name: 'Llama 3.1 70B',
    category: 'llm',
    provider: 'Meta',
    contextLength: 128000,
    speed: 'medium',
    quality: 'excellent',
    cost: 'low'
  },
  'llama-3.1-8b': {
    id: '@cf/meta/llama-3.1-8b-instruct',
    name: 'Llama 3.1 8B',
    category: 'llm',
    provider: 'Meta',
    contextLength: 128000,
    speed: 'fast',
    quality: 'good',
    cost: 'free'
  },
  'llama-3.3-70b': {
    id: '@cf/meta/llama-3.3-70b-instruct-fp8-fast',
    name: 'Llama 3.3 70B Fast',
    category: 'llm',
    provider: 'Meta',
    contextLength: 128000,
    speed: 'fast',
    quality: 'excellent',
    cost: 'low'
  },
  'deepseek-r1-32b': {
    id: '@cf/deepseek-ai/deepseek-r1-distill-qwen-32b',
    name: 'DeepSeek R1 32B',
    category: 'llm',
    provider: 'DeepSeek',
    contextLength: 32000,
    speed: 'medium',
    quality: 'excellent',
    cost: 'low'
  },
  'qwen-2.5-72b': {
    id: '@cf/qwen/qwen2.5-72b-instruct',
    name: 'Qwen 2.5 72B',
    category: 'llm',
    provider: 'Alibaba',
    contextLength: 32000,
    speed: 'medium',
    quality: 'excellent',
    cost: 'low'
  },
  'mistral-7b': {
    id: '@cf/mistral/mistral-7b-instruct-v0.2',
    name: 'Mistral 7B',
    category: 'llm',
    provider: 'Mistral',
    contextLength: 32000,
    speed: 'fast',
    quality: 'good',
    cost: 'free'
  },
  'hermes-2-pro': {
    id: '@hf/nousresearch/hermes-2-pro-mistral-7b',
    name: 'Hermes 2 Pro',
    category: 'llm',
    provider: 'NousResearch',
    contextLength: 32000,
    speed: 'fast',
    quality: 'good',
    cost: 'free'
  },
  'gemma-7b': {
    id: '@hf/google/gemma-7b-it',
    name: 'Gemma 7B',
    category: 'llm',
    provider: 'Google',
    contextLength: 8000,
    speed: 'fast',
    quality: 'good',
    cost: 'free'
  },
  
  // ğŸ–¼ï¸ Image Generation
  'flux-1-schnell': {
    id: '@cf/black-forest-labs/flux-1-schnell',
    name: 'FLUX.1 Schnell',
    category: 'image',
    provider: 'Black Forest Labs',
    speed: 'fast',
    quality: 'excellent',
    cost: 'low'
  },
  'stable-diffusion-xl': {
    id: '@cf/stabilityai/stable-diffusion-xl-base-1.0',
    name: 'Stable Diffusion XL',
    category: 'image',
    provider: 'Stability AI',
    speed: 'medium',
    quality: 'excellent',
    cost: 'low'
  },
  'dreamshaper-8-lcm': {
    id: '@cf/lykon/dreamshaper-8-lcm',
    name: 'DreamShaper 8 LCM',
    category: 'image',
    provider: 'Lykon',
    speed: 'fast',
    quality: 'good',
    cost: 'free'
  },
  
  // ğŸµ Audio
  'whisper-large': {
    id: '@cf/openai/whisper-large-v3-turbo',
    name: 'Whisper Large v3 Turbo',
    category: 'audio',
    provider: 'OpenAI',
    speed: 'fast',
    quality: 'excellent',
    cost: 'low'
  },
  'whisper-tiny': {
    id: '@cf/openai/whisper-tiny-en',
    name: 'Whisper Tiny (English)',
    category: 'audio',
    provider: 'OpenAI',
    speed: 'fast',
    quality: 'good',
    cost: 'free'
  },
  
  // ğŸ”¢ Embeddings
  'bge-base': {
    id: '@cf/baai/bge-base-en-v1.5',
    name: 'BGE Base',
    category: 'embedding',
    provider: 'BAAI',
    speed: 'fast',
    quality: 'excellent',
    cost: 'free'
  },
  'bge-large': {
    id: '@cf/baai/bge-large-en-v1.5',
    name: 'BGE Large',
    category: 'embedding',
    provider: 'BAAI',
    speed: 'medium',
    quality: 'excellent',
    cost: 'free'
  },
  
  // ğŸ‘ï¸ Vision
  'llava': {
    id: '@cf/llava-hf/llava-1.5-7b-hf',
    name: 'LLaVA 1.5',
    category: 'vision',
    provider: 'LLaVA',
    speed: 'medium',
    quality: 'good',
    cost: 'free'
  },
  
  // ğŸ’» Code
  'sqlcoder-7b': {
    id: '@cf/defog/sqlcoder-7b-2',
    name: 'SQLCoder 7B',
    category: 'code',
    provider: 'Defog',
    speed: 'fast',
    quality: 'excellent',
    cost: 'free'
  },
  'qwen-1.5-14b-chat': {
    id: '@cf/qwen/qwen1.5-14b-chat-awq',
    name: 'Qwen 1.5 14B',
    category: 'llm',
    provider: 'Alibaba',
    speed: 'medium',
    quality: 'good',
    cost: 'free'
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SMART ROUTING ENGINE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RouterEngine {
  private registry: Record<string, ModelConfig>;
  private metrics: Map<string, { latency: number[]; errors: number; calls: number }>;

  constructor(registry: Record<string, ModelConfig>) {
    this.registry = registry;
    this.metrics = new Map();
  }

  selectModel(category: string, strategy: RoutingStrategy): ModelConfig | null {
    const candidates = Object.values(this.registry).filter(m => m.category === category);
    
    if (candidates.length === 0) return null;

    if (strategy.type === 'specific' && strategy.modelId) {
      return this.registry[strategy.modelId] || null;
    }

    switch (strategy.type) {
      case 'fastest':
        return candidates.sort((a, b) => {
          const speedOrder = { fast: 0, medium: 1, slow: 2 };
          return speedOrder[a.speed] - speedOrder[b.speed];
        })[0];

      case 'best_quality':
        return candidates.sort((a, b) => {
          const qualityOrder = { excellent: 0, good: 1, basic: 2 };
          return qualityOrder[a.quality] - qualityOrder[b.quality];
        })[0];

      case 'lowest_cost':
        return candidates.sort((a, b) => {
          const costOrder = { free: 0, low: 1, medium: 2, high: 3 };
          return costOrder[a.cost] - costOrder[b.cost];
        })[0];

      case 'balanced':
      default:
        // Score = quality * speed * cost (lower is better)
        return candidates.sort((a, b) => {
          const scoreA = this.calculateScore(a);
          const scoreB = this.calculateScore(b);
          return scoreA - scoreB;
        })[0];
    }
  }

  private calculateScore(model: ModelConfig): number {
    const qualityScore = { excellent: 1, good: 2, basic: 3 }[model.quality];
    const speedScore = { fast: 1, medium: 2, slow: 3 }[model.speed];
    const costScore = { free: 1, low: 2, medium: 3, high: 4 }[model.cost];
    return qualityScore + speedScore + costScore;
  }

  recordMetric(modelId: string, latency: number, error: boolean) {
    const existing = this.metrics.get(modelId) || { latency: [], errors: 0, calls: 0 };
    existing.latency.push(latency);
    if (existing.latency.length > 100) existing.latency.shift();
    if (error) existing.errors++;
    existing.calls++;
    this.metrics.set(modelId, existing);
  }

  getMetrics(modelId: string) {
    const m = this.metrics.get(modelId);
    if (!m) return null;
    const avgLatency = m.latency.reduce((a, b) => a + b, 0) / m.latency.length;
    return {
      avgLatency: Math.round(avgLatency),
      errorRate: m.calls > 0 ? (m.errors / m.calls * 100).toFixed(2) + '%' : '0%',
      totalCalls: m.calls
    };
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// APP
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const app = new Hono<{ Bindings: Env }>();
const router = new RouterEngine(MODEL_REGISTRY);

app.use('*', cors({
  origin: '*',
  allowMethods: ['GET', 'POST', 'OPTIONS'],
  allowHeaders: ['Content-Type', 'Authorization']
}));

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ROUTES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app.get('/', (c) => c.json({
  service: 'NEURAL GATEWAY',
  version: '1.0.0',
  status: 'OPERATIONAL',
  totalModels: Object.keys(MODEL_REGISTRY).length,
  categories: ['llm', 'image', 'audio', 'embedding', 'vision', 'code'],
  features: ['smart-routing', 'load-balancing', 'caching', 'analytics'],
  timestamp: new Date().toISOString()
}));

// List all models
app.get('/models', (c) => {
  const category = c.req.query('category');
  let models = Object.entries(MODEL_REGISTRY);
  
  if (category) {
    models = models.filter(([_, m]) => m.category === category);
  }

  return c.json({
    success: true,
    count: models.length,
    models: models.map(([key, model]) => ({
      key,
      ...model,
      metrics: router.getMetrics(key)
    }))
  });
});

// Get specific model info
app.get('/models/:id', (c) => {
  const id = c.req.param('id');
  const model = MODEL_REGISTRY[id];
  
  if (!model) {
    return c.json({ success: false, error: 'Model not found' }, 404);
  }

  return c.json({
    success: true,
    model: {
      key: id,
      ...model,
      metrics: router.getMetrics(id)
    }
  });
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SMART INFERENCE ENDPOINTS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Chat / Text Generation - Routed
app.post('/chat', async (c) => {
  const startTime = Date.now();
  
  try {
    const { messages, strategy = 'balanced', model: specificModel } = await c.req.json();
    
    const routingStrategy: RoutingStrategy = specificModel 
      ? { type: 'specific', modelId: specificModel }
      : { type: strategy, fallback: true };

    const selectedModel = router.selectModel('llm', routingStrategy);
    
    if (!selectedModel) {
      return c.json({ success: false, error: 'No suitable model found' }, 400);
    }

    const result = await c.env.AI.run(selectedModel.id, { messages });
    const latency = Date.now() - startTime;
    
    router.recordMetric(selectedModel.name, latency, false);

    return c.json({
      success: true,
      response: result.response,
      model: selectedModel.name,
      strategy: routingStrategy.type,
      latency
    });
  } catch (error: any) {
    router.recordMetric('unknown', Date.now() - startTime, true);
    return c.json({ success: false, error: error.message }, 500);
  }
});

// Image Generation - Routed
app.post('/image', async (c) => {
  const startTime = Date.now();
  
  try {
    const { prompt, strategy = 'balanced', model: specificModel, width, height } = await c.req.json();
    
    const routingStrategy: RoutingStrategy = specificModel 
      ? { type: 'specific', modelId: specificModel }
      : { type: strategy, fallback: true };

    const selectedModel = router.selectModel('image', routingStrategy);
    
    if (!selectedModel) {
      return c.json({ success: false, error: 'No suitable image model found' }, 400);
    }

    const result = await c.env.AI.run(selectedModel.id, { 
      prompt,
      width: width || 1024,
      height: height || 1024
    });
    
    const latency = Date.now() - startTime;
    router.recordMetric(selectedModel.name, latency, false);

    // Return as base64
    const arrayBuffer = await result.arrayBuffer();
    const base64 = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

    return c.json({
      success: true,
      image: `data:image/png;base64,${base64}`,
      model: selectedModel.name,
      strategy: routingStrategy.type,
      latency
    });
  } catch (error: any) {
    router.recordMetric('unknown', Date.now() - startTime, true);
    return c.json({ success: false, error: error.message }, 500);
  }
});

// Transcription - Routed
app.post('/transcribe', async (c) => {
  const startTime = Date.now();
  
  try {
    const formData = await c.req.formData();
    const audio = formData.get('audio') as File;
    const strategy = formData.get('strategy') as string || 'balanced';
    
    if (!audio) {
      return c.json({ success: false, error: 'No audio file provided' }, 400);
    }

    const routingStrategy: RoutingStrategy = { type: strategy as any, fallback: true };
    const selectedModel = router.selectModel('audio', routingStrategy);
    
    if (!selectedModel) {
      return c.json({ success: false, error: 'No suitable audio model found' }, 400);
    }

    const audioBuffer = await audio.arrayBuffer();
    const result = await c.env.AI.run(selectedModel.id, { audio: [...new Uint8Array(audioBuffer)] });
    
    const latency = Date.now() - startTime;
    router.recordMetric(selectedModel.name, latency, false);

    return c.json({
      success: true,
      text: result.text,
      model: selectedModel.name,
      strategy: routingStrategy.type,
      latency
    });
  } catch (error: any) {
    router.recordMetric('unknown', Date.now() - startTime, true);
    return c.json({ success: false, error: error.message }, 500);
  }
});

// Embeddings - Routed
app.post('/embed', async (c) => {
  const startTime = Date.now();
  
  try {
    const { text, strategy = 'balanced', model: specificModel } = await c.req.json();
    
    const routingStrategy: RoutingStrategy = specificModel 
      ? { type: 'specific', modelId: specificModel }
      : { type: strategy, fallback: true };

    const selectedModel = router.selectModel('embedding', routingStrategy);
    
    if (!selectedModel) {
      return c.json({ success: false, error: 'No suitable embedding model found' }, 400);
    }

    const result = await c.env.AI.run(selectedModel.id, { text: [text] });
    const latency = Date.now() - startTime;
    
    router.recordMetric(selectedModel.name, latency, false);

    return c.json({
      success: true,
      embedding: result.data[0],
      dimensions: result.data[0]?.length || 0,
      model: selectedModel.name,
      strategy: routingStrategy.type,
      latency
    });
  } catch (error: any) {
    router.recordMetric('unknown', Date.now() - startTime, true);
    return c.json({ success: false, error: error.message }, 500);
  }
});

// SQL Generation - Specialized
app.post('/sql', async (c) => {
  const startTime = Date.now();
  
  try {
    const { question, schema, dialect = 'sqlite' } = await c.req.json();
    
    const model = MODEL_REGISTRY['sqlcoder-7b'];
    if (!model) {
      return c.json({ success: false, error: 'SQL model not available' }, 400);
    }

    const prompt = `### Task: Generate a SQL query to answer [QUESTION]${question}[/QUESTION]

### Database Schema:
${schema || 'No schema provided'}

### SQL Dialect: ${dialect}

### SQL Query:`;

    const result = await c.env.AI.run(model.id, { 
      prompt,
      max_tokens: 500
    });
    
    const latency = Date.now() - startTime;
    router.recordMetric(model.name, latency, false);

    return c.json({
      success: true,
      sql: result.response,
      model: model.name,
      latency
    });
  } catch (error: any) {
    router.recordMetric('unknown', Date.now() - startTime, true);
    return c.json({ success: false, error: error.message }, 500);
  }
});

// Vision - Image Analysis
app.post('/vision', async (c) => {
  const startTime = Date.now();
  
  try {
    const formData = await c.req.formData();
    const image = formData.get('image') as File;
    const question = formData.get('question') as string || 'What is in this image?';
    
    if (!image) {
      return c.json({ success: false, error: 'No image provided' }, 400);
    }

    const model = MODEL_REGISTRY['llava'];
    if (!model) {
      return c.json({ success: false, error: 'Vision model not available' }, 400);
    }

    const imageBuffer = await image.arrayBuffer();
    const base64 = btoa(String.fromCharCode(...new Uint8Array(imageBuffer)));

    const result = await c.env.AI.run(model.id, {
      prompt: question,
      image: [...new Uint8Array(imageBuffer)]
    });
    
    const latency = Date.now() - startTime;
    router.recordMetric(model.name, latency, false);

    return c.json({
      success: true,
      analysis: result.response,
      model: model.name,
      latency
    });
  } catch (error: any) {
    router.recordMetric('unknown', Date.now() - startTime, true);
    return c.json({ success: false, error: error.message }, 500);
  }
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ANALYTICS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app.get('/analytics', (c) => {
  const analytics: Record<string, any> = {};
  
  for (const [key, model] of Object.entries(MODEL_REGISTRY)) {
    const metrics = router.getMetrics(key);
    if (metrics && metrics.totalCalls > 0) {
      analytics[key] = {
        name: model.name,
        category: model.category,
        ...metrics
      };
    }
  }

  return c.json({
    success: true,
    analytics,
    timestamp: new Date().toISOString()
  });
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXPORT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export default app;
